{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "conservative-springfield",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Missing column provided to 'parse_dates': 'timestamp'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    175\u001b[0m selected_categories \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    176\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfood_cpi: Food\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    177\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfood_cpi: Meat\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfood_cpi: Bakery and cereal products (excluding baby food)\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    179\u001b[0m ]\n\u001b[1;32m    180\u001b[0m selected_models \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDeepAR\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTemporalFusionTransformer\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m--> 182\u001b[0m \u001b[43mgenerate_forecasts\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmerged_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmerged_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_cutoff\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m2025-08-01\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforecast_horizon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[43m    \u001b[49m\u001b[43mselected_categories\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mselected_categories\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    188\u001b[0m \u001b[43m    \u001b[49m\u001b[43mselected_models\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mselected_models\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtime_limit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1800\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# e.g. 2 min per category for testing\u001b[39;49;00m\n\u001b[1;32m    190\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36mgenerate_forecasts\u001b[0;34m(merged_path, output_dir, train_cutoff, forecast_horizon, selected_categories, selected_models, time_limit)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;124;03mTrain models up to a fixed cutoff and forecast into 2026.\u001b[39;00m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;124;03m    Training time limit per category (seconds)\u001b[39;00m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;66;03m# ------------------------------------------------------------------\u001b[39;00m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;66;03m# Load data\u001b[39;00m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;66;03m# ------------------------------------------------------------------\u001b[39;00m\n\u001b[0;32m---> 86\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmerged_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtimestamp\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m✅ Loaded dataset with shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     89\u001b[0m df_long \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mmelt(id_vars\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimestamp\u001b[39m\u001b[38;5;124m\"\u001b[39m], var_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mitem_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, value_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/cfpr_2025/cfpr_2025/miniconda3/envs/cfpr_2025_py3.8/lib/python3.8/site-packages/pandas/io/parsers/readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    899\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    900\u001b[0m     dialect,\n\u001b[1;32m    901\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    908\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    909\u001b[0m )\n\u001b[1;32m    910\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 912\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/cfpr_2025/cfpr_2025/miniconda3/envs/cfpr_2025_py3.8/lib/python3.8/site-packages/pandas/io/parsers/readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    574\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    576\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 577\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/cfpr_2025/cfpr_2025/miniconda3/envs/cfpr_2025_py3.8/lib/python3.8/site-packages/pandas/io/parsers/readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1404\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1406\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1407\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/cfpr_2025/cfpr_2025/miniconda3/envs/cfpr_2025_py3.8/lib/python3.8/site-packages/pandas/io/parsers/readers.py:1679\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1676\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[1;32m   1678\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1679\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmapping\u001b[49m\u001b[43m[\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1680\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1681\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/cfpr_2025/cfpr_2025/miniconda3/envs/cfpr_2025_py3.8/lib/python3.8/site-packages/pandas/io/parsers/c_parser_wrapper.py:161\u001b[0m, in \u001b[0;36mCParserWrapper.__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_usecols_names(\n\u001b[1;32m    156\u001b[0m             usecols,\n\u001b[1;32m    157\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnames,  \u001b[38;5;66;03m# type: ignore[has-type]\u001b[39;00m\n\u001b[1;32m    158\u001b[0m         )\n\u001b[1;32m    160\u001b[0m \u001b[38;5;66;03m# error: Cannot determine type of 'names'\u001b[39;00m\n\u001b[0;32m--> 161\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_parse_dates_presence\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnames\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[has-type]\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_noconvert_columns()\n\u001b[1;32m    164\u001b[0m \u001b[38;5;66;03m# error: Cannot determine type of 'names'\u001b[39;00m\n",
      "File \u001b[0;32m~/cfpr_2025/cfpr_2025/miniconda3/envs/cfpr_2025_py3.8/lib/python3.8/site-packages/pandas/io/parsers/base_parser.py:230\u001b[0m, in \u001b[0;36mParserBase._validate_parse_dates_presence\u001b[0;34m(self, columns)\u001b[0m\n\u001b[1;32m    220\u001b[0m missing_cols \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;28msorted\u001b[39m(\n\u001b[1;32m    222\u001b[0m         {\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    227\u001b[0m     )\n\u001b[1;32m    228\u001b[0m )\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m missing_cols:\n\u001b[0;32m--> 230\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    231\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing column provided to \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparse_dates\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmissing_cols\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    232\u001b[0m     )\n\u001b[1;32m    233\u001b[0m \u001b[38;5;66;03m# Convert positions to actual column names\u001b[39;00m\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[1;32m    235\u001b[0m     col \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(col, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m columns) \u001b[38;5;28;01melse\u001b[39;00m columns[col]\n\u001b[1;32m    236\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m cols_needed\n\u001b[1;32m    237\u001b[0m ]\n",
      "\u001b[0;31mValueError\u001b[0m: Missing column provided to 'parse_dates': 'timestamp'"
     ]
    }
   ],
   "source": [
    "# ======================================================================\n",
    "# 🔮 PARAMETERIZED FORECAST GENERATION SCRIPT (CFPR 2026)\n",
    "# ======================================================================\n",
    "\n",
    "import os\n",
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from autogluon.timeseries import TimeSeriesPredictor, TimeSeriesDataFrame\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 🧾 Helper: Save Forecasts in CFPR Standardized Format\n",
    "# ----------------------------------------------------------------------\n",
    "def save_standard_forecast(pred_df, category, model_name, forecast_year, output_root):\n",
    "    \"\"\"\n",
    "    Convert AutoGluon forecast DataFrame to standardized CFPR format:\n",
    "    ['timestamp', 'q_0.5', 'q_0.01', 'q_0.05', 'q_0.1', 'q_0.25', 'q_0.75', 'q_0.9', 'q_0.95', 'q_0.99']\n",
    "    \"\"\"\n",
    "    pred_df[\"timestamp\"] = pd.to_datetime(pred_df[\"timestamp\"], errors=\"coerce\")\n",
    "\n",
    "    quantile_cols = {\n",
    "        \"0.01\": \"q_0.01\", \"0.05\": \"q_0.05\", \"0.1\": \"q_0.1\",\n",
    "        \"0.25\": \"q_0.25\", \"0.5\": \"q_0.5\", \"0.75\": \"q_0.75\",\n",
    "        \"0.9\": \"q_0.9\", \"0.95\": \"q_0.95\", \"0.99\": \"q_0.99\"\n",
    "    }\n",
    "    pred_df = pred_df.rename(columns=quantile_cols)\n",
    "\n",
    "    # Fallback: if only mean exists\n",
    "    if \"mean\" in pred_df.columns and \"q_0.5\" not in pred_df.columns:\n",
    "        pred_df[\"q_0.5\"] = pred_df[\"mean\"]\n",
    "\n",
    "    # Ensure all expected columns exist\n",
    "    desired_cols = [\"timestamp\", \"q_0.5\", \"q_0.01\", \"q_0.05\", \"q_0.1\", \"q_0.25\",\n",
    "                    \"q_0.75\", \"q_0.9\", \"q_0.95\", \"q_0.99\"]\n",
    "    for col in desired_cols:\n",
    "        if col not in pred_df.columns:\n",
    "            pred_df[col] = np.nan\n",
    "    pred_df = pred_df[desired_cols]\n",
    "\n",
    "    pred_df = pred_df.round(3)\n",
    "\n",
    "    out_dir = os.path.join(output_root, category.replace(\"/\", \"_\"))\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    out_path = os.path.join(out_dir, f\"{category}_{model_name}_forecasts.csv\")\n",
    "    pred_df.to_csv(out_path, index=False)\n",
    "    print(f\"💾 Saved standardized forecast → {out_path}\")\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# ⚙️ MAIN FORECASTING PIPELINE\n",
    "# ----------------------------------------------------------------------\n",
    "def generate_forecasts(\n",
    "    merged_path,\n",
    "    output_dir,\n",
    "    train_cutoff=\"2025-08-01\",\n",
    "    forecast_horizon=16,\n",
    "    selected_categories=None,\n",
    "    selected_models=None,\n",
    "    time_limit=300,\n",
    "):\n",
    "    \"\"\"\n",
    "    Train models up to a fixed cutoff and forecast into 2026.\n",
    "    Parameters\n",
    "    ----------\n",
    "    merged_path : str\n",
    "        Path to merged CFPR dataset (must include timestamp + categories)\n",
    "    output_dir : str\n",
    "        Directory where forecast outputs will be saved\n",
    "    train_cutoff : str\n",
    "        Cutoff date for training (default '2025-08-01')\n",
    "    forecast_horizon : int\n",
    "        How many months ahead to forecast (default 16)\n",
    "    selected_categories : list or None\n",
    "        Food categories to forecast; if None → use all in dataset\n",
    "    selected_models : list or None\n",
    "        Models to train; if None → use default list\n",
    "    time_limit : int\n",
    "        Training time limit per category (seconds)\n",
    "    \"\"\"\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # Load data\n",
    "    # ------------------------------------------------------------------\n",
    "    df = pd.read_csv(merged_path, parse_dates=[\"timestamp\"])\n",
    "    print(f\"✅ Loaded dataset with shape {df.shape}\")\n",
    "\n",
    "    df_long = df.melt(id_vars=[\"timestamp\"], var_name=\"item_id\", value_name=\"target\")\n",
    "    ts_df = TimeSeriesDataFrame.from_data_frame(df_long, id_column=\"item_id\", timestamp_column=\"timestamp\")\n",
    "\n",
    "    all_categories = ts_df.index.get_level_values(\"item_id\").unique().tolist()\n",
    "    if selected_categories is None:\n",
    "        selected_categories = all_categories\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # Select models\n",
    "    # ------------------------------------------------------------------\n",
    "    if selected_models is None:\n",
    "        selected_models = [\n",
    "            \"DeepAR\",\n",
    "            \"AutoETS\",\n",
    "            \"TemporalFusionTransformer\",\n",
    "            \"SimpleFeedForward\",\n",
    "        ]\n",
    "        if torch.cuda.is_available():\n",
    "            selected_models.append(\"Chronos\")\n",
    "\n",
    "    print(f\"🧩 Using models: {selected_models}\")\n",
    "    print(f\"🍱 Forecasting {len(selected_categories)} categories (up to {train_cutoff})\")\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # Forecast Loop\n",
    "    # ------------------------------------------------------------------\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    train_cutoff_ts = pd.Timestamp(train_cutoff)\n",
    "\n",
    "    for category in selected_categories:\n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        print(f\"🔮 Generating forecasts for: {category}\")\n",
    "        print(\"=\" * 70)\n",
    "\n",
    "        cat_ts = ts_df.loc[[category]]\n",
    "        train_data = cat_ts.loc[cat_ts.index.get_level_values(\"timestamp\") <= train_cutoff_ts]\n",
    "\n",
    "        # Sanity check\n",
    "        print(f\"📆 Training range: {train_data.index.get_level_values('timestamp').min().date()} → {train_data.index.get_level_values('timestamp').max().date()}\")\n",
    "\n",
    "        save_dir = os.path.join(output_dir, category.replace(\"/\", \"_\"))\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "        # Train model\n",
    "        predictor = TimeSeriesPredictor(\n",
    "            target=\"target\",\n",
    "            prediction_length=forecast_horizon,\n",
    "            freq=\"MS\",\n",
    "            path=save_dir,\n",
    "            eval_metric=\"MAPE\",\n",
    "        )\n",
    "\n",
    "        start_time = time.time()\n",
    "        predictor.fit(\n",
    "            train_data=train_data,\n",
    "            presets=\"medium_quality\",\n",
    "            time_limit=time_limit,\n",
    "            hyperparameters={m: {} for m in selected_models},\n",
    "        )\n",
    "        train_duration = time.time() - start_time\n",
    "        print(f\"✅ Finished training {category} in {train_duration:.1f} sec\")\n",
    "\n",
    "        # Predict into the future (2025-09 → 2026-12)\n",
    "        trained_models = predictor.get_model_names()\n",
    "        print(f\"🧩 Trained models: {trained_models}\")\n",
    "\n",
    "        for model_name in trained_models:\n",
    "            try:\n",
    "                print(f\"📈 Predicting with {model_name} ...\")\n",
    "                pred_df = predictor.predict(train_data, model=model_name).reset_index()\n",
    "                save_standard_forecast(pred_df, category, model_name, \"2026\", output_dir)\n",
    "            except Exception as e:\n",
    "                print(f\"⚠️ Skipping {model_name} for {category} due to error: {e}\")\n",
    "                continue\n",
    "\n",
    "    print(\"\\n✅ ALL FORECASTS GENERATED AND SAVED SUCCESSFULLY ✅\")\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 🏁 Example Usage\n",
    "# ----------------------------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    merged_path = \"/h/kupfersk/cfpr_2026/data_limited_2026/CFPR_2026_master_dataset.csv\"\n",
    "    output_dir = \"/h/kupfersk/cfpr_2026/generate_forecasts/output/Forecasts_2026\"\n",
    "\n",
    "    # Example: pick categories and models\n",
    "    food_categories = [\n",
    "        \"Bakery and cereal products (excluding baby food)\",\n",
    "        \"Dairy products and eggs\",\n",
    "        \"Fish, seafood and other marine products\",\n",
    "        \"Food purchased from restaurants\",\n",
    "        \"Food\",\n",
    "        \"Fruit, fruit preparations and nuts\",\n",
    "        \"Meat\",\n",
    "        \"Other food products and non-alcoholic beverages\",\n",
    "        \"Vegetables and vegetable preparations\",\n",
    "    ]\n",
    "\n",
    "    selected_models = [\"DeepAR\", \"TemporalFusionTransformer\"]\n",
    "\n",
    "    generate_forecasts(\n",
    "        merged_path=merged_path,\n",
    "        output_dir=output_dir,\n",
    "        train_cutoff=\"2025-08-01\",\n",
    "        forecast_horizon=16,\n",
    "        selected_categories=selected_categories,\n",
    "        selected_models=selected_models,\n",
    "        time_limit=1800,  # e.g. 2 min per category for testing\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "veterinary-waste",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rising-nutrition",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cfpr_2025_py3.8",
   "language": "python",
   "name": "cfpr_2025_py3.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
