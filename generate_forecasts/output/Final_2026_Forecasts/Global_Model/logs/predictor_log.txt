Beginning AutoGluon training... Time limit = 6s
AutoGluon will save models to '/h/kupfersk/cfpr_2026/generate_forecasts/output/Final_2026_Forecasts/Global_Model'
=================== System Info ===================
AutoGluon Version:  1.1.1
Python Version:     3.8.20
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #167~18.04.1-Ubuntu SMP Wed May 24 00:51:42 UTC 2023
CPU Count:          40
GPU Count:          0
Memory Avail:       113.55 GB / 125.17 GB (90.7%)
Disk Space Avail:   25319.02 GB / 249006.62 GB (10.2%)
===================================================
Setting presets to: medium_quality

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'freq': 'MS',
 'hyperparameters': {'DeepAR': {}, 'TemporalFusionTransformer': {}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 16,
 'quantile_levels': [0.01, 0.05, 0.1, 0.25, 0.5, 0.75, 0.9, 0.95, 0.99],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 6,
 'verbosity': 2}

Provided train_data has 4284 rows, 9 time series. Median time series length is 476 (min=476, max=476). 

Provided data contains following columns:
	target: 'target'
	past_covariates:
		categorical:        []
		continuous (float): ['Geopolitical_clean', 'Climate', 'Manufacturing', 'Economic']

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-10-23 09:18:31
Models that will be trained: ['TemporalFusionTransformer', 'DeepAR']
Training timeseries model TemporalFusionTransformer. Training for up to 2.0s of the 6.0s of remaining time.
	-0.0561       = Validation score (-MAPE)
	2.16    s     = Training runtime
	0.05    s     = Validation (prediction) runtime
Training timeseries model DeepAR. Training for up to 1.9s of the 3.7s of remaining time.
	-0.0537       = Validation score (-MAPE)
	1.86    s     = Training runtime
	0.14    s     = Validation (prediction) runtime
Fitting simple weighted ensemble.
	Ensemble weights: {'DeepAR': 1.0}
	-0.0537       = Validation score (-MAPE)
	0.32    s     = Training runtime
	0.14    s     = Validation (prediction) runtime
Training complete. Models trained: ['TemporalFusionTransformer', 'DeepAR', 'WeightedEnsemble']
Total runtime: 4.58 s
Best model: DeepAR
Best model score: -0.0537
Warning: path already exists! This predictor may overwrite an existing predictor! path="/h/kupfersk/cfpr_2026/generate_forecasts/output/Final_2026_Forecasts/Global_Model"
Beginning AutoGluon training... Time limit = 6s
Beginning AutoGluon training... Time limit = 6s
AutoGluon will save models to '/h/kupfersk/cfpr_2026/generate_forecasts/output/Final_2026_Forecasts/Global_Model'
AutoGluon will save models to '/h/kupfersk/cfpr_2026/generate_forecasts/output/Final_2026_Forecasts/Global_Model'
=================== System Info ===================
AutoGluon Version:  1.1.1
Python Version:     3.8.20
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #167~18.04.1-Ubuntu SMP Wed May 24 00:51:42 UTC 2023
CPU Count:          40
GPU Count:          0
Memory Avail:       113.49 GB / 125.17 GB (90.7%)
Disk Space Avail:   25314.12 GB / 249006.62 GB (10.2%)
===================================================
=================== System Info ===================
AutoGluon Version:  1.1.1
Python Version:     3.8.20
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #167~18.04.1-Ubuntu SMP Wed May 24 00:51:42 UTC 2023
CPU Count:          40
GPU Count:          0
Memory Avail:       113.49 GB / 125.17 GB (90.7%)
Disk Space Avail:   25314.12 GB / 249006.62 GB (10.2%)
===================================================
Setting presets to: medium_quality
Setting presets to: medium_quality

Fitting with arguments:

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'freq': 'MS',
 'hyperparameters': {'DeepAR': {}, 'TemporalFusionTransformer': {}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 16,
 'quantile_levels': [0.01, 0.05, 0.1, 0.25, 0.5, 0.75, 0.9, 0.95, 0.99],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 6,
 'verbosity': 2}

{'enable_ensemble': True,
 'eval_metric': MAPE,
 'freq': 'MS',
 'hyperparameters': {'DeepAR': {}, 'TemporalFusionTransformer': {}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 16,
 'quantile_levels': [0.01, 0.05, 0.1, 0.25, 0.5, 0.75, 0.9, 0.95, 0.99],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 6,
 'verbosity': 2}

Provided train_data has 4284 rows, 9 time series. Median time series length is 476 (min=476, max=476). 
Provided train_data has 4284 rows, 9 time series. Median time series length is 476 (min=476, max=476). 

Provided data contains following columns:

Provided data contains following columns:
	target: 'target'
	target: 'target'
	past_covariates:
	past_covariates:
		categorical:        []
		categorical:        []
		continuous (float): ['Geopolitical_clean', 'Climate', 'Manufacturing', 'Economic']
		continuous (float): ['Geopolitical_clean', 'Climate', 'Manufacturing', 'Economic']

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================
===================================================

Starting training. Start time is 2025-10-23 09:26:48

Starting training. Start time is 2025-10-23 09:26:48
Models that will be trained: ['TemporalFusionTransformer', 'DeepAR']
Models that will be trained: ['TemporalFusionTransformer', 'DeepAR']
Training timeseries model TemporalFusionTransformer. Training for up to 2.0s of the 6.0s of remaining time.
Training timeseries model TemporalFusionTransformer. Training for up to 2.0s of the 6.0s of remaining time.
	-0.0497       = Validation score (-MAPE)
	-0.0497       = Validation score (-MAPE)
	2.18    s     = Training runtime
	2.18    s     = Training runtime
	0.04    s     = Validation (prediction) runtime
	0.04    s     = Validation (prediction) runtime
Training timeseries model DeepAR. Training for up to 1.9s of the 3.7s of remaining time.
Training timeseries model DeepAR. Training for up to 1.9s of the 3.7s of remaining time.
	-0.0538       = Validation score (-MAPE)
	-0.0538       = Validation score (-MAPE)
	1.86    s     = Training runtime
	1.86    s     = Training runtime
	0.13    s     = Validation (prediction) runtime
	0.13    s     = Validation (prediction) runtime
Fitting simple weighted ensemble.
Fitting simple weighted ensemble.
	Ensemble weights: {'TemporalFusionTransformer': 1.0}
	Ensemble weights: {'TemporalFusionTransformer': 1.0}
	-0.0497       = Validation score (-MAPE)
	-0.0497       = Validation score (-MAPE)
	0.33    s     = Training runtime
	0.33    s     = Training runtime
	0.04    s     = Validation (prediction) runtime
	0.04    s     = Validation (prediction) runtime
Training complete. Models trained: ['TemporalFusionTransformer', 'DeepAR', 'WeightedEnsemble']
Training complete. Models trained: ['TemporalFusionTransformer', 'DeepAR', 'WeightedEnsemble']
Total runtime: 4.61 s
Total runtime: 4.61 s
Best model: TemporalFusionTransformer
Best model: TemporalFusionTransformer
Best model score: -0.0497
Best model score: -0.0497
Beginning AutoGluon training... Time limit = 6s
AutoGluon will save models to '/h/kupfersk/cfpr_2026/generate_forecasts/output/Final_2026_Forecasts/Global_Model'
=================== System Info ===================
AutoGluon Version:  1.1.1
Python Version:     3.8.20
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #167~18.04.1-Ubuntu SMP Wed May 24 00:51:42 UTC 2023
CPU Count:          40
GPU Count:          0
Memory Avail:       113.61 GB / 125.17 GB (90.8%)
Disk Space Avail:   25313.87 GB / 249006.62 GB (10.2%)
===================================================
Setting presets to: medium_quality

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'freq': 'MS',
 'hyperparameters': {'DeepAR': {}, 'TemporalFusionTransformer': {}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 16,
 'quantile_levels': [0.01, 0.05, 0.1, 0.25, 0.5, 0.75, 0.9, 0.95, 0.99],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 6,
 'verbosity': 2}

Provided train_data has 4284 rows, 9 time series. Median time series length is 476 (min=476, max=476). 

Provided data contains following columns:
	target: 'target'
	past_covariates:
		categorical:        []
		continuous (float): ['Geopolitical_clean', 'Climate', 'Manufacturing', 'Economic']

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-10-23 09:32:50
Models that will be trained: ['TemporalFusionTransformer', 'DeepAR']
Training timeseries model TemporalFusionTransformer. Training for up to 2.0s of the 6.0s of remaining time.
	-0.0528       = Validation score (-MAPE)
	2.17    s     = Training runtime
	0.04    s     = Validation (prediction) runtime
Training timeseries model DeepAR. Training for up to 1.9s of the 3.7s of remaining time.
	-0.0486       = Validation score (-MAPE)
	1.86    s     = Training runtime
	0.14    s     = Validation (prediction) runtime
Fitting simple weighted ensemble.
	Ensemble weights: {'DeepAR': 1.0}
	-0.0486       = Validation score (-MAPE)
	0.32    s     = Training runtime
	0.14    s     = Validation (prediction) runtime
Training complete. Models trained: ['TemporalFusionTransformer', 'DeepAR', 'WeightedEnsemble']
Total runtime: 4.58 s
Best model: DeepAR
Best model score: -0.0486
Beginning AutoGluon training... Time limit = 1800s
AutoGluon will save models to '/h/kupfersk/cfpr_2026/generate_forecasts/output/Final_2026_Forecasts/Global_Model'
=================== System Info ===================
AutoGluon Version:  1.1.1
Python Version:     3.8.20
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #147~18.04.1-Ubuntu SMP Sat Oct 15 13:10:18 UTC 2022
CPU Count:          32
GPU Count:          1
Memory Avail:       171.03 GB / 188.59 GB (90.7%)
Disk Space Avail:   25311.90 GB / 249006.62 GB (10.2%)
===================================================
Setting presets to: medium_quality

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MAPE,
 'freq': 'MS',
 'hyperparameters': {'Chronos': {},
                     'DeepAR': {},
                     'TemporalFusionTransformer': {}},
 'known_covariates_names': [],
 'num_val_windows': 1,
 'prediction_length': 16,
 'quantile_levels': [0.01, 0.05, 0.1, 0.25, 0.5, 0.75, 0.9, 0.95, 0.99],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'target',
 'time_limit': 1800,
 'verbosity': 2}

Provided train_data has 4284 rows, 9 time series. Median time series length is 476 (min=476, max=476). 

Provided data contains following columns:
	target: 'target'
	past_covariates:
		categorical:        []
		continuous (float): ['Geopolitical_clean', 'Climate', 'Manufacturing', 'Economic']

To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit

AutoGluon will gauge predictive performance using evaluation metric: 'MAPE'
	This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.
===================================================

Starting training. Start time is 2025-10-23 09:55:44
Models that will be trained: ['Chronos[autogluon__chronos-t5-small]', 'TemporalFusionTransformer', 'DeepAR']
Training timeseries model Chronos[autogluon__chronos-t5-small]. Training for up to 450.0s of the 1800.0s of remaining time.
	-0.0157       = Validation score (-MAPE)
	0.01    s     = Training runtime
	1.06    s     = Validation (prediction) runtime
Training timeseries model TemporalFusionTransformer. Training for up to 599.6s of the 1798.9s of remaining time.
	-0.0124       = Validation score (-MAPE)
	180.11  s     = Training runtime
	0.04    s     = Validation (prediction) runtime
Training timeseries model DeepAR. Training for up to 1018.7s of the 1618.7s of remaining time.
	-0.0196       = Validation score (-MAPE)
	72.46   s     = Training runtime
	0.12    s     = Validation (prediction) runtime
Fitting simple weighted ensemble.
	Ensemble weights: {'Chronos[autogluon__chronos-t5-small]': 0.24, 'DeepAR': 0.06, 'TemporalFusionTransformer': 0.7}
	-0.0109       = Validation score (-MAPE)
	0.55    s     = Training runtime
	1.22    s     = Validation (prediction) runtime
Training complete. Models trained: ['Chronos[autogluon__chronos-t5-small]', 'TemporalFusionTransformer', 'DeepAR', 'WeightedEnsemble']
Total runtime: 254.46 s
Best model: WeightedEnsemble
Best model score: -0.0109
