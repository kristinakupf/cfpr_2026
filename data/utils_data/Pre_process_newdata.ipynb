{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1c6dcf1-d2bd-4776-a30a-08a29567792f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa2f4917-8e4c-4151-b503-8c7f3b9e8ada",
   "metadata": {},
   "source": [
    "# SWE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d68bdc6-52a5-4d18-95c0-df221f8c74fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CDEC_swe_nl.csv\n",
      "IDC,\n",
      "INN,\n",
      "TK2,\n",
      "MSK,\n",
      "HVN,\n",
      "HGM,\n",
      "MRL,\n",
      "EP5,\n",
      "RP2,\n",
      "TCC,\n",
      "WC3,\n",
      "EBB,\n",
      "PSN,\n",
      "LVT,\n",
      "VRG,\n",
      "LVM,\n",
      "CDEC_swe_nc.csv\n",
      "MB3,\n",
      "RRM,\n",
      "SHM,\n",
      "HIG,\n",
      "CDEC_swe_sl.csv\n",
      "GEM,\n",
      "SWM,\n",
      "CDEC_swe_sr.csv\n",
      "SLT,\n",
      "CDEC_swe_sj.csv\n",
      "BLK,\n",
      "CDEC_swe_tl.csv\n",
      "BSH,\n",
      "BCB,\n",
      "UBC,\n",
      "FRW,\n",
      "CBT,\n",
      "CSV,\n"
     ]
    }
   ],
   "source": [
    "data_path = '../raw_data/'\n",
    "all_data = os.listdir(data_path)\n",
    "\n",
    "for datasource in all_data:\n",
    "    if 'swe' in datasource:\n",
    "        print(datasource)\n",
    "        df =  pd.read_csv(data_path + datasource)\n",
    "        station_ids = df['STATION_ID'].unique()\n",
    "\n",
    "        for ind_id in station_ids:\n",
    "            print(f\"{ind_id},\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294d80b2-0c6d-45d4-b7f9-6eaca9770c0b",
   "metadata": {},
   "source": [
    "# FRED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e15240a-ab82-49f1-a322-7c996bd9c40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rename FRED csvs to follow old naming convention\n",
    "data_path = '../raw_data_updated/'\n",
    "\n",
    "all_data = os.listdir(data_path)\n",
    "for datasource in all_data:\n",
    "    if not any(elem in datasource for elem in ['CDEC', 'PDSI', 'EPU', 'swe']):\n",
    "        if '.csv' in datasource:\n",
    "            filename = datasource\n",
    "\n",
    "#             new_filename = f\"FRED_{filename.lower().split('fred_')[0]}\"\n",
    "\n",
    "#             # Construct the full paths\n",
    "#             old_file = os.path.join(data_path, filename)\n",
    "#             new_file = os.path.join(data_path, new_filename)\n",
    "\n",
    "#             # Rename the file\n",
    "#             os.rename(old_file, new_file)\n",
    "#             print(f\"Renamed: {filename} to {new_filename}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "geological-precipitation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'FRED_pcu325311325311-Copy1.csv'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "logical-array",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['wb_commodity_price_index.csv']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename.lower().split('fred_')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696062e5-c5bc-4d51-b460-ebe1de78b7ca",
   "metadata": {},
   "source": [
    "# PDSI "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04595dc4-c6e0-4339-a084-3cc029b88bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cody pre-processed data and saved in a .csv form. If raw the first three values are the state/region and the last four values are the year\n",
    "df = pd.read_csv('../raw_data_updated/PDSI.csv').set_index('Year').drop(columns='Column')\n",
    "\n",
    "#Explore state codes and their meaning for explanatory purposes\n",
    "codes_df = pd.read_csv('../raw_data_updated/PDSI_State_Codes.csv')\n",
    "\n",
    "#Make a list of important regions \n",
    "#used anything that had mention of corn and wheat \n",
    "important_regions = [250, 255, 256, 260, 261, 262, 265, 350, 356, 361, 362]\n",
    "\n",
    "#(https://beef2live.com/story-states-produce-food-value-0-107252 used this as a reference)\n",
    "important_states = [4, 13, 25, 41, 11]\n",
    "\n",
    "codes_df = codes_df.loc[codes_df['Code'].isin(important_regions+important_states)].set_index('Code')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "electrical-sunset",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length of values (1560) does not match length of index (3120)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m         df_out \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({name:single_list})\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 23\u001b[0m         df_out[name] \u001b[38;5;241m=\u001b[39m single_list\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m#Assign a date to each of the values\u001b[39;00m\n\u001b[1;32m     27\u001b[0m dates \u001b[38;5;241m=\u001b[39m get_dates(df)\n",
      "File \u001b[0;32m~/cfpr_2025/cfpr_2025/miniconda3/envs/cfpr_2025_py3.8/lib/python3.8/site-packages/pandas/core/frame.py:3980\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3977\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_array([key], value)\n\u001b[1;32m   3978\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3979\u001b[0m     \u001b[38;5;66;03m# set column\u001b[39;00m\n\u001b[0;32m-> 3980\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_item\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/cfpr_2025/cfpr_2025/miniconda3/envs/cfpr_2025_py3.8/lib/python3.8/site-packages/pandas/core/frame.py:4174\u001b[0m, in \u001b[0;36mDataFrame._set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   4164\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_set_item\u001b[39m(\u001b[38;5;28mself\u001b[39m, key, value) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   4165\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4166\u001b[0m \u001b[38;5;124;03m    Add series to DataFrame in specified column.\u001b[39;00m\n\u001b[1;32m   4167\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4172\u001b[0m \u001b[38;5;124;03m    ensure homogeneity.\u001b[39;00m\n\u001b[1;32m   4173\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4174\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sanitize_column\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4176\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   4177\u001b[0m         key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[1;32m   4178\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m value\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   4179\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_extension_array_dtype(value)\n\u001b[1;32m   4180\u001b[0m     ):\n\u001b[1;32m   4181\u001b[0m         \u001b[38;5;66;03m# broadcast across multiple columns if necessary\u001b[39;00m\n\u001b[1;32m   4182\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mis_unique \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns, MultiIndex):\n",
      "File \u001b[0;32m~/cfpr_2025/cfpr_2025/miniconda3/envs/cfpr_2025_py3.8/lib/python3.8/site-packages/pandas/core/frame.py:4915\u001b[0m, in \u001b[0;36mDataFrame._sanitize_column\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m   4912\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _reindex_for_setitem(Series(value), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex)\n\u001b[1;32m   4914\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_list_like(value):\n\u001b[0;32m-> 4915\u001b[0m     \u001b[43mcom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequire_length_match\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sanitize_array(value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, allow_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/cfpr_2025/cfpr_2025/miniconda3/envs/cfpr_2025_py3.8/lib/python3.8/site-packages/pandas/core/common.py:571\u001b[0m, in \u001b[0;36mrequire_length_match\u001b[0;34m(data, index)\u001b[0m\n\u001b[1;32m    567\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    568\u001b[0m \u001b[38;5;124;03mCheck the length of data matches the length of the index.\u001b[39;00m\n\u001b[1;32m    569\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    570\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(index):\n\u001b[0;32m--> 571\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    572\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLength of values \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    573\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    574\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdoes not match length of index \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    575\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(index)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    576\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Length of values (1560) does not match length of index (3120)"
     ]
    }
   ],
   "source": [
    "#Filter to exclusively include important regions\n",
    "df = df.loc[df['State'].isin(important_regions+important_states)]\n",
    "\n",
    "#Create individual time series for each regions with the names\n",
    "vars_to_include = important_regions+important_states\n",
    "for current_var in vars_to_include:\n",
    "    name = codes_df.loc[codes_df.index == current_var]['State'].values[0]\n",
    "    df_code = df.loc[df['State'].isin([current_var])].drop(columns=['State', 'Code'])\n",
    "\n",
    "    single_series = []\n",
    "\n",
    "    #Create a single time-series for each important variable\n",
    "    for year in df_code.T.columns:\n",
    "        single_series.append(df_code.T[year].values)\n",
    "    #     print(len(enso_series))\n",
    "\n",
    "    single_list = [item for sublist in single_series for item in sublist]\n",
    "\n",
    "    if current_var == vars_to_include[0]: #if first time through\n",
    "        df_out = pd.DataFrame({name:single_list})\n",
    "        \n",
    "    else:\n",
    "        df_out[name] = single_list\n",
    "\n",
    "\n",
    "#Assign a date to each of the values\n",
    "dates = get_dates(df)\n",
    "\n",
    "df_out['date'] = dates\n",
    "\n",
    "# Unpopulated values appear as -99.99, replace with NaN\n",
    "df_out = df_out.replace(-99.99, pd.np.nan).set_index('date')\n",
    "\n",
    "pdsi_df = df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "divine-mexican",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WB_commodity_price_index-Copy1.csv\n"
     ]
    }
   ],
   "source": [
    "data_path = '../raw_data_updated/'\n",
    "for source in os.listdir(data_path):\n",
    "    if 'Copy' in source:\n",
    "        print(source)\n",
    "        old_file_path = os.path.join(data_path, source)\n",
    "        splitname = source.split('-Copy1')\n",
    "        new_name = splitname[0] + '.csv'\n",
    "        \n",
    "        \n",
    "        new_file_path = os.path.join(data_path, new_name)\n",
    "    \n",
    "        if os.path.exists(old_file_path):\n",
    "            os.rename(old_file_path, new_file_path)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abandoned-window",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cfpr_2025_py3.8",
   "language": "python",
   "name": "cfpr_2025_py3.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
